{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Python standard library\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Scientific computing\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "sys.path.append('../functions')\n",
    "import functions\n",
    "\n",
    "\n",
    "\n",
    "# Imports the Google Cloud client library\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision import types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../img/insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name of the image file to annotate\n",
    "file_directory = '/home/prestonh/shelfy/shelfy/img/insight/'\n",
    "file_name = 'insight_1.jpg'\n",
    "file_path = file_directory + file_name\n",
    "\n",
    "\n",
    "\n",
    "# Instantiates a client\n",
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "\n",
    "\n",
    "# Loads the image into memory\n",
    "img_file = file_path\n",
    "with io.open(img_file, 'rb') as image_file:\n",
    "    content = image_file.read()\n",
    "img_bin = types.Image(content=content)\n",
    "\n",
    "\n",
    "\n",
    "# Ask for response; get response annotations\n",
    "response = client.document_text_detection(image=img_bin)\n",
    "texts = response.text_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The name of the image file to annotate\n",
    "file_directory = '/home/prestonh/shelfy/shelfy/img/insight/'\n",
    "file_name = 'insight_1.jpg'\n",
    "file_path = file_directory + file_name\n",
    "\n",
    "# Load and look at the image\n",
    "print(file_path)\n",
    "img = cv2.imread(file_path, 0)\n",
    "\n",
    "print(img.shape)\n",
    "\n",
    "\n",
    "plt.imshow(img, cmap = 'gray')\n",
    "plt.show()\n",
    "\n",
    "# Instantiates a client\n",
    "client = vision.ImageAnnotatorClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the image into memory\n",
    "\n",
    "img_file = file_path\n",
    "with io.open(img_file, 'rb') as image_file:\n",
    "    content = image_file.read()\n",
    "img_bin = types.Image(content=content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "response = client.document_text_detection(image=img_bin)\n",
    "texts = response.text_annotations\n",
    "print('response type:', type(response))\n",
    "print('texts type:', type(texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert google to shelfy form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "words = [functions.Word.FromGoogleText(text) for text in texts[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "functions.PlotBoxedImage_Words(img, words)\n",
    "print([word.string for word in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_filter(word):\n",
    "    # Length based filtering\n",
    "    length_filter = len(word.string) > 1\n",
    "    \n",
    "    return length_filter\n",
    "\n",
    "words = [word for word in words if word_filter(word)]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.PlotBoxedImage_Words(img, words, show = False)\n",
    "#plt.savefig()\n",
    "plt.show()\n",
    "print([word.string for word in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spine detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithmic approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spines = functions.GetSpines(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, spine in enumerate(spines):\n",
    "    \n",
    "    print([word.string for word in spine.words])\n",
    "    fig = plt.figure(figsize = (16,12))\n",
    "    functions.PlotAnnotatedImage_Words(img, [word for word in spine.words], show = False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.savefig(file_path.replace('.jpg', '_' + str(i) + '.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spine in spines:\n",
    "    book_info = ''\n",
    "    for word in spine.words:\n",
    "        book_info += word.string + ' '\n",
    "    print(book_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetGoogleSearchLink(search_query):\n",
    "    return 'https://www.google.com/search?q='+search_query\n",
    "\n",
    "def GetBookInfo(search_query):\n",
    "    link = GetAmazonLinkFromGoogleSearch(search_query)\n",
    "    return GetTitleFromAmazon(link)\n",
    "    \n",
    "\n",
    "def GetAmazonLinkFromGoogleSearch(search_query):\n",
    "    \n",
    "    # Perform google search\n",
    "    link = GetGoogleSearchLink(search_query)\n",
    "    \n",
    "    ua = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.116 Safari/537.36'}                                                                \n",
    "\n",
    "    response = requests.get(link, headers=ua)\n",
    "    content = response.content\n",
    "    \n",
    "    # Parse for amazon link\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    for link in soup.find_all('a'):\n",
    "        url = link.get('href')\n",
    "        if 'amazon' in str(url):\n",
    "            return url\n",
    "        \n",
    "def GetTitleFromAmazon(url):\n",
    "    ua = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_8_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/27.0.1453.116 Safari/537.36'}                                                                \n",
    "    response = requests.get(url, headers=ua)\n",
    "    content = response.content\n",
    "\n",
    "    # Parse for amazon link\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Title\n",
    "    title = soup.find_all(id='productTitle')[0].contents[0]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Author\n",
    "    author = soup.find_all(class_ = 'a-link-normal contributorNameID')[0].contents[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # ISBN-13\n",
    "    isbn_13 = soup.find_all(class_ = 'a-size-base a-color-base')[0].contents\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # ISBN-10\n",
    "    isbn_10 = soup.find_all(class_ = 'a-size-base a-color-base')[1].contents\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return title, author\n",
    "    \n",
    "        \n",
    "        \n",
    "\n",
    "for spine in spines:\n",
    "    \n",
    "    book_info = ''\n",
    "    for word in spine.words:\n",
    "        book_info += word.string + ' '\n",
    "        \n",
    "    time.sleep(1)\n",
    "    print(book_info)\n",
    "    print(GetBookInfo(book_info))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
