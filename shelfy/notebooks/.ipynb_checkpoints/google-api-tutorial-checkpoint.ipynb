{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.cloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fc90c27577fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Imports the Google Cloud client library\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.cloud'"
     ]
    }
   ],
   "source": [
    "# Python standard library\n",
    "import io\n",
    "import os\n",
    "\n",
    "# Scientific computing\n",
    "#c.IPKernelApp.pyplot = u'inline'\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "# Imports the Google Cloud client library\n",
    "from google.cloud import vision\n",
    "from google.cloud.vision import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Image data can not convert to float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-790a02bdb111>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/prestonh/anaconda3/envs/py36/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3155\u001b[0m                         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3156\u001b[0m                         \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3157\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   3158\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3159\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/prestonh/anaconda3/envs/py36/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1896\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1897\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/prestonh/anaconda3/envs/py36/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5122\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5124\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5125\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/prestonh/anaconda3/envs/py36/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    594\u001b[0m         if (self._A.dtype != np.uint8 and\n\u001b[1;32m    595\u001b[0m                 not np.can_cast(self._A.dtype, np.float)):\n\u001b[0;32m--> 596\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image data can not convert to float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         if (self._A.ndim not in (2, 3) or\n",
      "\u001b[0;31mTypeError\u001b[0m: Image data can not convert to float"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQYAAAD8CAYAAACVSwr3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADCtJREFUeJzt21+IZvV9x/H3p7tZaEwaJTsJ6e5Kt2WNbttYdGIkhNY0\ntO6aiyXghRoqlcAixJBLpdCk4E1zUQjBP8sii+QmexNJN2UTW1oSC9bGWVDXVZTpSt1VwVVDCgYq\ng99ezNP0yXx3d86szzzPTn2/YGDOOb+Z82WY5z1nzpxJVSFJ435j1gNIuvgYBkmNYZDUGAZJjWGQ\n1BgGSc2qYUhyKMnrSZ49x/Ek+U6SxSTPJLlm8mNKmqYhVwwPA3vOc3wvsGv0th948L2PJWmWVg1D\nVT0GvHWeJfuA79ayJ4BLk3xiUgNKmr7NE/gc24BTY9unR/teW7kwyX6Wryq45JJLrr3yyisncHpJ\n53Ls2LE3qmpurR83iTAMVlUHgYMA8/PztbCwMM3TS+87Sf7zQj5uEn+VeAXYMba9fbRP0gY1iTAc\nAW4f/XXieuAXVdV+jZC0caz6q0SS7wE3AFuTnAa+CXwAoKoOAEeBm4BF4JfAHes1rKTpWDUMVXXr\nKscL+OrEJpI0cz75KKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkx\nDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEM\nkhrDIKkxDJIawyCpMQySGsMgqRkUhiR7kryQZDHJPWc5/pEkP0zydJITSe6Y/KiSpmXVMCTZBNwP\n7AV2A7cm2b1i2VeB56rqauAG4O+SbJnwrJKmZMgVw3XAYlWdrKp3gMPAvhVrCvhwkgAfAt4CliY6\nqaSpGRKGbcCpse3To33j7gOuAl4FjgNfr6p3V36iJPuTLCRZOHPmzAWOLGm9Term443AU8BvA38E\n3Jfkt1YuqqqDVTVfVfNzc3MTOrWkSRsShleAHWPb20f7xt0BPFLLFoGXgCsnM6KkaRsShieBXUl2\njm4o3gIcWbHmZeALAEk+DnwSODnJQSVNz+bVFlTVUpK7gEeBTcChqjqR5M7R8QPAvcDDSY4DAe6u\nqjfWcW5J62jVMABU1VHg6Ip9B8befxX488mOJmlWfPJRUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMY\nJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgk\nNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1g8KQZE+SF5IsJrnnHGtuSPJUkhNJ\nfjrZMSVN0+bVFiTZBNwP/BlwGngyyZGqem5szaXAA8Ceqno5ycfWa2BJ62/IFcN1wGJVnayqd4DD\nwL4Va24DHqmqlwGq6vXJjilpmoaEYRtwamz79GjfuCuAy5L8JMmxJLef7RMl2Z9kIcnCmTNnLmxi\nSetuUjcfNwPXAl8EbgT+OskVKxdV1cGqmq+q+bm5uQmdWtKkrXqPAXgF2DG2vX20b9xp4M2qeht4\nO8ljwNXAixOZUtJUDblieBLYlWRnki3ALcCRFWv+Hvhcks1JPgh8Bnh+sqNKmpZVrxiqainJXcCj\nwCbgUFWdSHLn6PiBqno+yY+BZ4B3gYeq6tn1HFzS+klVzeTE8/PztbCwMJNzS+8XSY5V1fxaP84n\nHyU1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMY\nJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNYZBUmMYJDWGQVJjGCQ1hkFSYxgk\nNYZBUmMYJDWDwpBkT5IXkiwmuec86z6dZCnJzZMbUdK0rRqGJJuA+4G9wG7g1iS7z7HuW8A/TnpI\nSdM15IrhOmCxqk5W1TvAYWDfWdZ9Dfg+8PoE55M0A0PCsA04NbZ9erTvV5JsA74EPHi+T5Rkf5KF\nJAtnzpxZ66ySpmRSNx+/DdxdVe+eb1FVHayq+aqan5ubm9CpJU3a5gFrXgF2jG1vH+0bNw8cTgKw\nFbgpyVJV/WAiU0qaqiFheBLYlWQny0G4BbhtfEFV7fzf95M8DPyDUZA2rlXDUFVLSe4CHgU2AYeq\n6kSSO0fHD6zzjJKmbMgVA1V1FDi6Yt9Zg1BVf/nex5I0Sz75KKkxDJIawyCpMQySGsMgqTEMkhrD\nIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySGsMg\nqTEMkhrDIKkxDJIawyCpMQySGsMgqTEMkhrDIKkxDJIawyCpMQySmkFhSLInyQtJFpPcc5bjX07y\nTJLjSR5PcvXkR5U0LauGIckm4H5gL7AbuDXJ7hXLXgL+pKr+ELgXODjpQSVNz5ArhuuAxao6WVXv\nAIeBfeMLqurxqvr5aPMJYPtkx5Q0TUPCsA04NbZ9erTvXL4C/OhsB5LsT7KQZOHMmTPDp5Q0VRO9\n+Zjk8yyH4e6zHa+qg1U1X1Xzc3Nzkzy1pAnaPGDNK8COse3to32/JsmngIeAvVX15mTGkzQLQ64Y\nngR2JdmZZAtwC3BkfEGSy4FHgL+oqhcnP6akaVr1iqGqlpLcBTwKbAIOVdWJJHeOjh8AvgF8FHgg\nCcBSVc2v39iS1lOqaiYnnp+fr4WFhZmcW3q/SHLsQn5I++SjpMYwSGoMg6TGMEhqDIOkxjBIagyD\npMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOk\nxjBIagyDpMYwSGoMg6TGMEhqDIOkxjBIagyDpMYwSGoMg6TGMEhqDIOkZlAYkuxJ8kKSxST3nOV4\nknxndPyZJNdMflRJ07JqGJJsAu4H9gK7gVuT7F6xbC+wa/S2H3hwwnNKmqIhVwzXAYtVdbKq3gEO\nA/tWrNkHfLeWPQFcmuQTE55V0pRsHrBmG3BqbPs08JkBa7YBr40vSrKf5SsKgP9O8uyapp2trcAb\nsx5ioI00K2yseTfSrACfvJAPGhKGiamqg8BBgCQLVTU/zfO/Fxtp3o00K2yseTfSrLA874V83JBf\nJV4Bdoxtbx/tW+saSRvEkDA8CexKsjPJFuAW4MiKNUeA20d/nbge+EVVvbbyE0naGFb9VaKqlpLc\nBTwKbAIOVdWJJHeOjh8AjgI3AYvAL4E7Bpz74AVPPRsbad6NNCtsrHk30qxwgfOmqiY9iKQNzicf\nJTWGQVKz7mHYSI9TD5j1y6MZjyd5PMnVs5hzbJ7zzju27tNJlpLcPM35Vsyw6qxJbkjyVJITSX46\n7RlXzLLa98JHkvwwydOjeYfcV1sXSQ4lef1czwVd0GusqtbtjeWblf8B/C6wBXga2L1izU3Aj4AA\n1wP/vp4zvcdZPwtcNnp/76xmHTrv2Lp/YfkG8c0X66zApcBzwOWj7Y9dzF9b4K+Ab43enwPeArbM\naN4/Bq4Bnj3H8TW/xtb7imEjPU696qxV9XhV/Xy0+QTLz2vMypCvLcDXgO8Dr09zuBWGzHob8EhV\nvQxQVRf7vAV8OEmAD7EchqXpjjkapOqx0fnPZc2vsfUOw7kelV7rmmlY6xxfYbnCs7LqvEm2AV9i\n9v/UNuRrewVwWZKfJDmW5PapTdcNmfc+4CrgVeA48PWqenc6463Zml9jU30k+v+LJJ9nOQyfm/Us\nq/g2cHdVvbv8g+2ithm4FvgC8JvAvyV5oqpenO1Y53Qj8BTwp8DvAf+U5F+r6r9mO9ZkrHcYNtLj\n1IPmSPIp4CFgb1W9OaXZzmbIvPPA4VEUtgI3JVmqqh9MZ8RfGTLraeDNqnobeDvJY8DVwCzCMGTe\nO4C/reVf4heTvARcCfxsOiOuydpfY+t8U2QzcBLYyf/dxPn9FWu+yK/fGPnZjG7gDJn1cpaf7vzs\nLGZc67wr1j/M7G4+DvnaXgX882jtB4FngT+4iOd9EPib0fsfH73Qts7w++F3OPfNxzW/xtb1iqHW\n73HqWc36DeCjwAOjn8JLNaP/tBs470VhyKxV9XySHwPPAO8CD1XVTP4tf+DX9l7g4STHWX7B3V1V\nM/l37CTfA24AtiY5DXwT+MDYrGt+jflItKTGJx8lNYZBUmMYJDWGQVJjGCQ1hkFSYxgkNf8DUTBP\njjp5sn4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb06fe260b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The name of the image file to annotate\n",
    "file_directory = '/home/prestonh/bookshelf/img/'\n",
    "file_name = 'insight_shelf_0.jpg'\n",
    "file_path = file_directory + file_name\n",
    "\n",
    "# Load and look at the image\n",
    "img = cv2.imread(file_path, 0)\n",
    "\n",
    "\n",
    "plt.imshow(img, cmap = 'gray')\n",
    "plt.show()\n",
    "\n",
    "# Instantiates a client\n",
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "# Loads the image into memory\n",
    "with io.open(file_path, 'rb') as image_file:\n",
    "    content = image_file.read()\n",
    "img_bin = types.Image(content=content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-67671a2a2799>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_text_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_bin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_annotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'response type:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'texts type:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "response = client.document_text_detection(image=img_bin)\n",
    "\n",
    "texts = response.text_annotations\n",
    "print('response type:', type(response))\n",
    "print('texts type:', type(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Word(object):\n",
    "    '''\n",
    "    Simple Word class consisting of the word\"s value ('string') and the bounding box ('bounding_box')\n",
    "    containing the word\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, string, bounding_box):\n",
    "        self.string = string\n",
    "        self.bounding_box = bounding_box\n",
    "        \n",
    "    def FromGoogleText(google_text):\n",
    "        '''\n",
    "        Converts a google text_annotation into a simpler Word format\n",
    "        args:\n",
    "            google_text: the google text_annotation object\n",
    "        '''\n",
    "        \n",
    "        string = google_text.description\n",
    "        bounding_box = BoundingBox.FromGoogleBoundingPoly(google_text.bounding_poly)\n",
    "        \n",
    "        return Word(string, bounding_box)\n",
    "        \n",
    "\n",
    "class BoundingBox(object):\n",
    "    def __init__(self, xs, ys):\n",
    "        self.xs = xs\n",
    "        self.ys = ys\n",
    "        \n",
    "    def Center(self):\n",
    "        '''\n",
    "        Returns the center of the bounding box object\n",
    "        '''\n",
    "        xc = (self.xs[0] + self.xs[1] + self.xs[2] + self.xs[3])/4.\n",
    "        yc = (self.ys[0] + self.ys[1] + self.ys[2] + self.ys[3])/4.\n",
    "        \n",
    "        return xc, yc\n",
    "    \n",
    "\n",
    "    def ImageToBoundingBoxCoordinateTransformation(self, x, y):\n",
    "        '''\n",
    "        The coordinate frame of the bounding box is defined by its center (the origin), the long-axis\n",
    "        (x-axis, or along the spine usually), and the short-axis (y-axis, lateral to spine direction usually)\n",
    "        This takes coordinates\n",
    "        '''\n",
    "        long_axis_angle = self.LongAxisAngle()\n",
    "        xc, yc = self.Center()\n",
    "        \n",
    "        xp = np.cos(long_axis_angle)*(x-xc) + np.sin(long_axis_angle)*(y-yc)\n",
    "        yp = -np.sin(long_axis_angle)*(x-xc) + np.cos(long_axis_angle)*(y-yc)\n",
    "        \n",
    "        return (xp, yp)\n",
    "    \n",
    "    def FitLine(self):\n",
    "        '''\n",
    "        Gets the line in the form y=mx+b (returns slope and y-intercept) of the bounding box object.\n",
    "        Does this by finding the long axis angle and center\n",
    "        Returned as a tuple\n",
    "        '''\n",
    "        \n",
    "        center = self.Center()\n",
    "        x = center[0]\n",
    "        y = center[1]\n",
    "        \n",
    "        m = np.tan(self.LongAxisAngle())\n",
    "        b = y-m*x\n",
    "        \n",
    "        return (m, b)\n",
    "    \n",
    "    def LongAxisAngle(self):\n",
    "        '''\n",
    "        Returns the long axis angle of the bounding box object\n",
    "        '''\n",
    "        \n",
    "        l1 = (self.ys[1]-self.ys[0])**2. + (self.xs[1]-self.xs[0])**2.\n",
    "        l2 = (self.ys[2]-self.ys[1])**2. + (self.xs[2]-self.xs[1])**2.\n",
    "        \n",
    "        \n",
    "        if l1 >= l2:\n",
    "            return np.arctan2(self.ys[1]-self.ys[0], self.xs[1]-self.xs[0])\n",
    "        else:\n",
    "            return np.arctan2(self.ys[2]-self.ys[1], self.xs[2]-self.xs[1])\n",
    "        \n",
    "    \n",
    "    def ShortAxisAngle(self):\n",
    "        '''\n",
    "        Returns the short axis of the bounding box object\n",
    "        '''\n",
    "        \n",
    "        l1 = (self.ys[1]-self.ys[0])**2. + (self.xs[1]-self.xs[0])**2.\n",
    "        l2 = (self.ys[2]-self.ys[1])**2. + (self.xs[2]-self.xs[1])**2.\n",
    "        \n",
    "        \n",
    "        if l1 <= l2:\n",
    "            return np.arctan2(self.ys[1]-self.ys[0], self.xs[1]-self.xs[0])\n",
    "        else:\n",
    "            return np.arctan2(self.ys[2]-self.ys[1], self.xs[2]-self.xs[1])\n",
    "\n",
    "        \n",
    "    \n",
    "    def FromGoogleBoundingPoly(bounding_poly):\n",
    "        '''\n",
    "        Factory function for creating a vertex from a bounding poly\n",
    "        args:\n",
    "            bounding_poly: the bounding_poly object\n",
    "        '''\n",
    "        \n",
    "        xs = []\n",
    "        ys = []\n",
    "        for vertex in bounding_poly.vertices:\n",
    "            xs.append(vertex.x)\n",
    "            ys.append(vertex.y)\n",
    "        \n",
    "        return BoundingBox(xs, ys)\n",
    "        \n",
    "        \n",
    "\n",
    "def GoogleBoundingPolyToVertices(bounding_poly):\n",
    "    '''\n",
    "    Converts the vertices in a bounding_poly object to a list of tuples (more convenient\n",
    "    to work with)\n",
    "    args:\n",
    "        bounding_poly: The bounding_poly object\n",
    "    '''\n",
    "    \n",
    "    for vertex in bounding_poly.vertices:\n",
    "        x = vertex.x\n",
    "        y = vertex.y\n",
    "        vertices.append((x,y))\n",
    "        \n",
    "    return vertices\n",
    "    \n",
    "def PlotAnnotatedImage(img, words):\n",
    "    if type(words) == 'text_annotations':\n",
    "        PlotAnnotatedImage_GoogleCloudVision()\n",
    "    elif type(words) == '__main__.Words':\n",
    "        PlotAnnotatedImage_Words()\n",
    "    \n",
    "def PlotAnnotatedImage_Words(img, words, color = 'red', show = True):\n",
    "    '''\n",
    "    Plots an image alongside all of the bounding boxes found by the GoogleCloudVision \n",
    "    document_text_detection() function\n",
    "    args:\n",
    "        img: the img, should be in normal numpy format\n",
    "        texts: the text_annotations object returned by the GoogleCloudVision api\n",
    "    '''\n",
    "    \n",
    "    for word in words:\n",
    "        if color == 'random':\n",
    "            color = np.random.rand(3)*1.\n",
    "        bb = word.bounding_box\n",
    "        plt.plot([bb.xs[0], bb.xs[1]], [bb.ys[0], bb.ys[1]], lw = 3, c = color)\n",
    "        plt.plot([bb.xs[1], bb.xs[2]], [bb.ys[1], bb.ys[2]], lw = 3, c = color)\n",
    "        plt.plot([bb.xs[2], bb.xs[3]], [bb.ys[2], bb.ys[3]], lw = 3, c = color)\n",
    "        plt.plot([bb.xs[3], bb.xs[0]], [bb.ys[3], bb.ys[0]], lw = 3, c = color)\n",
    "        \n",
    "    plt.imshow(img, cmap = 'gray')\n",
    "    \n",
    "    if show:\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    \n",
    "def PlotAnnotatedImage_GoogleCloudVision(img, texts):\n",
    "    '''\n",
    "    Plots an image alongside all of the bounding boxes found by the GoogleCloudVision \n",
    "    document_text_detection() function\n",
    "    args:\n",
    "        img: the img, should be in normal numpy format\n",
    "        texts: the text_annotations object returned by the GoogleCloudVision api\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    \n",
    "    for text in texts:\n",
    "        bb = BoundingBox.FromGoogleBoundingPoly(text.bounding_poly)\n",
    "        plt.plot([bb.xs[0], bb.xs[1]], [bb.ys[0], bb.ys[1]], lw = 3, c = 'r')\n",
    "        plt.plot([bb.xs[1], bb.xs[2]], [bb.ys[1], bb.ys[2]], lw = 3, c = 'r')\n",
    "        plt.plot([bb.xs[2], bb.xs[3]], [bb.ys[2], bb.ys[3]], lw = 3, c = 'r')\n",
    "        plt.plot([bb.xs[3], bb.xs[0]], [bb.ys[3], bb.ys[0]], lw = 3, c = 'r')\n",
    "    \n",
    "    plt.imshow(img, cmap = 'gray')\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = [Word.FromGoogleText(text) for text in texts[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ix = 51\n",
    "word = words[ix]\n",
    "other_words = [words[i] for i in range(len(words)) if i != ix]\n",
    "PlotAnnotatedImage_Words(img, [words[ix]], color = 'random', show = False)\n",
    "\n",
    "center = word.bounding_box.Center()\n",
    "long_axis_angle = word.bounding_box.LongAxisAngle()\n",
    "short_axis_angle = word.bounding_box.ShortAxisAngle()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(word.bounding_box.Center())\n",
    "print(word.bounding_box.LongAxisAngle()*180/np.pi)\n",
    "print(word.bounding_box.ShortAxisAngle()*180/np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "long_axis_angle = word.bounding_box.LongAxisAngle()\n",
    "print(long_axis_angle)\n",
    "\n",
    "centers = np.array([words[i].bounding_box.Center() for i in range(len(words))])\n",
    "centers = centers - centers[0]\n",
    "\n",
    "\n",
    "theta = word.bounding_box.LongAxisAngle()\n",
    "rot_matrix = np.array([[np.cos(theta), np.sin(theta)],[-np.sin(theta), np.cos(theta)]])\n",
    "\n",
    "for i in range(len(centers)):\n",
    "    centers[i,:] = np.dot(rot_matrix, centers[i,:].reshape(-1,1)).flatten()\n",
    "    \n",
    "angles = [word.bounding_box.LongAxisAngle() for word in words]\n",
    "plt.scatter(angles[ix], centers[ix,1], marker = 'x', c = 'red')\n",
    "plt.scatter(angles[1:], centers[1:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in words:\n",
    "    plt.scatter(word.bounding_box.Center()[0], word.bounding_box.ShortAxisAngle()*180/np.pi)\n",
    "plt.xlabel('x'), plt.ylabel('angle')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "for word in words:\n",
    "    plt.scatter(word.bounding_box.Center()[0], word.bounding_box.LongAxisAngle()*180/np.pi)\n",
    "plt.xlabel('y'), plt.ylabel('angle')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in words:\n",
    "    \n",
    "    plt.scatter(word.bounding_box.Center()[0], word.bounding_box.Center()[1])\n",
    "    \n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PlotAnnotatedImage_GoogleCloudVision(img, texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for text in texts:\n",
    "    print('\\n\"{}\"'.format(text.description))\n",
    "\n",
    "    vertices = (['({},{})'.format(vertex.x, vertex.y) for vertex in text.bounding_poly.vertices])\n",
    "\n",
    "    print('bounds: {}'.format(','.join(vertices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_text(path):\n",
    "    \"\"\"Detects text in the file.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = types.Image(content=content)\n",
    "\n",
    "    response = client.text_detection(image=image)\n",
    "    texts = response.text_annotations\n",
    "    print('Texts:')\n",
    "\n",
    "    for text in texts:\n",
    "        print('\\n\"{}\"'.format(text.description))\n",
    "\n",
    "        vertices = (['({},{})'.format(vertex.x, vertex.y)\n",
    "                    for vertex in text.bounding_poly.vertices])\n",
    "\n",
    "        print('bounds: {}'.format(','.join(vertices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
