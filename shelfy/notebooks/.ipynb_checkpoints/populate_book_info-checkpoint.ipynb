{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import sys\n",
    "\n",
    "\n",
    "import numpy\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "\n",
    "\n",
    "import shelfy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create SQL DB connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://postgres:password@localhost:5432/book_info\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Define a database name (we're using a dataset on births, so we'll call it birth_db)\n",
    "# Set your postgres username/password, and connection specifics\n",
    "username = 'postgres'\n",
    "password = 'password'     # change this\n",
    "host     = 'localhost'\n",
    "port     = '5432'            # default port that postgres listens on\n",
    "db_name  = 'book_info'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 'engine' is a connection to a database\n",
    "## Here, we're using postgres, but sqlalchemy can connect to other things too.\n",
    "engine = create_engine( 'postgresql://{}:{}@{}:{}/{}'.format(username, password, host, port, db_name) )\n",
    "print(engine.url)\n",
    "\n",
    "\n",
    "## create a database (if it doesn't exist)\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "print(database_exists(engine.url))\n",
    "\n",
    "\n",
    "\n",
    "# Create connection and cursor object to insert info into db\n",
    "con = psycopg2.connect(database = db_name, user = username, password = password, host = host)\n",
    "cursor = con.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create titles table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the tables (if don't exist)\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS works (\n",
    "                index BIGSERIAL PRIMARY KEY,\n",
    "                titles TEXT);''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS editions (\n",
    "                index BIGSERIAL PRIMARY KEY,\n",
    "                titles TEXT);''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS authors (\n",
    "                index BIGSERIAL PRIMARY KEY,\n",
    "                authors TEXT);''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS publishers (\n",
    "                index BIGSERIAL PRIMARY KEY,\n",
    "                publishers TEXT);''')\n",
    "\n",
    "\n",
    "# Have to commit the table creation\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fill titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed 1\n",
      "failed 2\n",
      "failed 3\n",
      "failed 4\n",
      "failed 5\n",
      "failed 6\n",
      "failed 7\n",
      "failed 8\n",
      "failed 9\n",
      "failed 10\n",
      "failed 11\n",
      "failed 12\n",
      "failed 13\n",
      "failed 14\n",
      "failed 15\n",
      "failed 16\n",
      "failed 17\n",
      "failed 18\n",
      "failed 19\n",
      "failed 20\n",
      "failed 21\n",
      "failed 22\n",
      "failed 23\n",
      "failed 24\n",
      "failed 25\n",
      "failed 26\n",
      "failed 27\n",
      "failed 28\n",
      "failed 29\n",
      "failed 30\n",
      "failed 31\n",
      "failed 32\n",
      "failed 33\n",
      "failed 34\n",
      "failed 35\n",
      "failed 36\n",
      "failed 37\n",
      "failed 38\n",
      "failed 39\n",
      "failed 40\n",
      "failed 41\n",
      "failed 42\n",
      "failed 43\n",
      "failed 44\n",
      "failed 45\n",
      "failed 46\n",
      "failed 47\n",
      "failed 48\n",
      "failed 49\n",
      "failed 50\n",
      "failed 51\n",
      "failed 52\n",
      "failed 53\n",
      "failed 54\n",
      "failed 55\n",
      "failed 56\n",
      "failed 57\n",
      "failed 58\n",
      "failed 59\n",
      "failed 60\n",
      "failed 61\n",
      "failed 62\n",
      "failed 63\n",
      "failed 64\n",
      "failed 65\n",
      "failed 66\n",
      "failed 67\n",
      "failed 68\n",
      "failed 69\n",
      "failed 70\n",
      "failed 71\n",
      "failed 72\n",
      "failed 73\n",
      "failed 74\n",
      "failed 75\n",
      "failed 76\n",
      "failed 77\n",
      "failed 78\n",
      "failed 79\n",
      "failed 80\n",
      "failed 81\n",
      "failed 82\n",
      "failed 83\n",
      "failed 84\n",
      "failed 85\n",
      "failed 86\n",
      "failed 87\n",
      "failed 88\n",
      "failed 89\n",
      "failed 90\n",
      "failed 91\n",
      "failed 92\n",
      "failed 93\n",
      "failed 94\n",
      "failed 95\n",
      "failed 96\n",
      "failed 97\n",
      "failed 98\n",
      "failed 99\n",
      "failed 100\n",
      "failed 101\n",
      "failed 102\n",
      "failed 103\n",
      "failed 104\n",
      "failed 105\n",
      "failed 106\n",
      "failed 107\n",
      "failed 108\n",
      "failed 109\n",
      "failed 110\n",
      "failed 111\n",
      "failed 112\n",
      "failed 113\n",
      "failed 114\n",
      "failed 115\n",
      "failed 116\n",
      "failed 117\n",
      "failed 118\n",
      "failed 119\n",
      "failed 120\n",
      "failed 121\n",
      "failed 122\n",
      "failed 123\n",
      "failed 124\n",
      "failed 125\n",
      "failed 126\n",
      "failed 127\n",
      "failed 128\n",
      "failed 129\n",
      "failed 130\n",
      "failed 131\n",
      "failed 132\n",
      "failed 133\n",
      "failed 134\n",
      "failed 135\n",
      "failed 136\n",
      "failed 137\n",
      "failed 138\n",
      "failed 139\n",
      "failed 140\n",
      "failed 141\n",
      "failed 142\n",
      "failed 143\n",
      "failed 144\n",
      "failed 145\n",
      "failed 146\n",
      "failed 147\n",
      "failed 148\n",
      "failed 149\n",
      "failed 150\n",
      "failed 151\n",
      "failed 152\n",
      "failed 153\n",
      "failed 154\n",
      "failed 155\n",
      "failed 156\n",
      "failed 157\n",
      "failed 158\n",
      "failed 159\n",
      "failed 160\n",
      "failed 161\n",
      "failed 162\n",
      "failed 163\n",
      "failed 164\n",
      "failed 165\n",
      "failed 166\n",
      "failed 167\n",
      "failed 168\n",
      "failed 169\n",
      "failed 170\n",
      "failed 171\n",
      "failed 172\n",
      "failed 173\n",
      "failed 174\n",
      "failed 175\n",
      "failed 176\n",
      "failed 177\n",
      "failed 178\n",
      "failed 179\n",
      "failed 180\n",
      "failed 181\n",
      "failed 182\n",
      "failed 183\n",
      "failed 184\n",
      "failed 185\n",
      "failed 186\n",
      "failed 187\n",
      "failed 188\n",
      "failed 189\n",
      "failed 190\n",
      "failed 191\n",
      "failed 192\n",
      "failed 193\n",
      "failed 194\n",
      "failed 195\n",
      "failed 196\n",
      "failed 197\n",
      "failed 198\n",
      "failed 199\n",
      "failed 200\n",
      "failed 201\n",
      "failed 202\n",
      "failed 203\n",
      "failed 204\n",
      "failed 205\n",
      "failed 206\n",
      "failed 207\n",
      "failed 208\n",
      "failed 209\n",
      "failed 210\n",
      "failed 211\n",
      "failed 212\n",
      "failed 213\n",
      "failed 214\n",
      "failed 215\n",
      "failed 216\n"
     ]
    }
   ],
   "source": [
    "# Works\n",
    "command = '''INSERT INTO works (titles) VALUES (%s);'''\n",
    "\n",
    "\n",
    "titles_path = shelfy.SHELFY_BASE_PATH + '/raw_data/dumps/' + 'ol_dump_works_2017-12-31.txt'\n",
    "\n",
    "\n",
    "num_fails = 0\n",
    "with open(titles_path, 'r') as file_handle:\n",
    "    \n",
    "    for row in file_handle:\n",
    "        try:\n",
    "            title = json.loads(row.split('\\t')[-1])['title']\n",
    "            cursor.execute(command, (title,))\n",
    "            con.commit()\n",
    "        except:\n",
    "            num_fails += 1\n",
    "            print('failed', num_fails)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fill editions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parliamentary Debates, House of Lords, Bound Volumes, 1992-93\n"
     ]
    }
   ],
   "source": [
    "# Editions\n",
    "\n",
    "command = '''INSERT INTO editions (titles) VALUES (%s);'''\n",
    "\n",
    "\n",
    "titles_path = shelfy.SHELFY_BASE_PATH + '/raw_data/dumps/' + 'ol_dump_editions_2017-12-31.txt'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_fails = 0\n",
    "with open(titles_path, 'r') as file_handle:\n",
    "    \n",
    "    \n",
    "    i = 0\n",
    "    # Open reader object to parse file\n",
    "    for row in file_handle:\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        try:\n",
    "            title = json.loads(row.split('\\t')[4])['title']\n",
    "            cursor.execute(command, (title,))\n",
    "            \n",
    "        except:\n",
    "            num_fails += 1\n",
    "            print('failed', num_fails)\n",
    "            pass\n",
    "        \n",
    "        if i % 10000 == 0:\n",
    "            print('dumping 10000')\n",
    "            con.commit()\n",
    "            i = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = '../data/jsondump.json'\n",
    "\n",
    "table_name = 'titles'\n",
    "\n",
    "batch_size = 10000\n",
    "\n",
    "with open(file_name, 'r') as file_handle:\n",
    "\n",
    "    ix = 0\n",
    "    while ix < 10:\n",
    "        titles = []\n",
    "        subtitles = [] \n",
    "        authors = []\n",
    "        publishers = []\n",
    "        isbn10s = []\n",
    "        isbns13 = []\n",
    "\n",
    "        print('starting a new block, num_blocks = ', ix)\n",
    "        ix += 1\n",
    "\n",
    "        for i in range(batch_size):\n",
    "\n",
    "            data = next(file_handle)\n",
    "            json_data = json.loads(data)\n",
    "\n",
    "            keys = json_data.keys()\n",
    "\n",
    "            \n",
    "\n",
    "            if json_data['type']['key'] == '/type/edition':\n",
    "\n",
    "\n",
    "                print(json_data)\n",
    "\n",
    "                if 'isbn_13' in keys:\n",
    "                    isbn_13 = json_data['isbn_13'][0]\n",
    "                else:\n",
    "                    isbn_13 = random_isbn()\n",
    "\n",
    "\n",
    "                if 'isbn_10' in keys:\n",
    "                    isbn_10 = json_data['isbn_10'][0]\n",
    "                else:\n",
    "                    isbn_10 = 'NULL'\n",
    "\n",
    "\n",
    "                if 'title' in keys:\n",
    "                    title = json_data['title']\n",
    "                else:\n",
    "                    title = 'NULL'\n",
    "\n",
    "                if 'subtitle' in keys:\n",
    "                    subtitle = json_data['subtitle']\n",
    "                else:\n",
    "                    subtitle = 'NULL'\n",
    "\n",
    "                if 'publishers' in keys:\n",
    "                    publisher = json_data['publishers'][0]\n",
    "                else:\n",
    "                    publisher = []\n",
    "\n",
    "\n",
    "\n",
    "                command = '''\n",
    "                INSERT INTO titles (isbn_13, isbn_10, title, subtitle, publisher) VALUES (%s, %s, %s, %s, %s);\n",
    "                '''\n",
    "\n",
    "                try:\n",
    "                    #cursor.execute(command, (isbn_13, isbn_10, title, subtitle, publisher))\n",
    "                    pass\n",
    "                except Exception as e:\n",
    "                    print(str(e))\n",
    "                    print('error!', ix)\n",
    "                    #con.commit()\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "        con.commit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create titles_2 database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor.execute('''CREATE TABLE IF NOT EXISTS works (\n",
    "                work_key text primary key,\n",
    "                title text\n",
    "               );''')\n",
    "\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = '../data/ol_dump_works_2017-12-31.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(file_name) as file_handle:\n",
    "\n",
    "    while True:\n",
    "        line = next(file_handle)\n",
    "        json_start = line.find('{')\n",
    "        json_data = json.loads(line[json_start:])\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            title = json_data['title']\n",
    "            work_key = json_data['key'].split('/')[-1]\n",
    "    \n",
    "            command = '''\n",
    "            INSERT INTO works (work_key, title) VALUES (%s, %s)\n",
    "            '''\n",
    "        \n",
    "            cursor.execute(command, (work_key, title))\n",
    "            con.commit()\n",
    "        except Exception as e:\n",
    "            print('error')\n",
    "            print(str(e))\n",
    "            con.commit()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('asdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create authors database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor.execute('''CREATE TABLE IF NOT EXISTS authors (\n",
    "                author_id text primary key,\n",
    "                author_name text\n",
    "               );''')\n",
    "\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = '../data/ol_dump_authors_2017-12-31.txt'\n",
    "\n",
    "with open(file_name) as file_handle:\n",
    "    while True:\n",
    "        line = next(file_handle)\n",
    "        author_id = line.split('/authors/')[-1].split(' ')[0].replace('\",', '')\n",
    "        author_name = line.split('{\"name\": ')[-1].split(',')[0].replace('\"','')\n",
    "        \n",
    "        command = '''\n",
    "        INSERT INTO authors (author_id, author_name) VALUES (%s, %s);\n",
    "        '''\n",
    "        \n",
    "        cursor.execute(command, (author_id, author_name))\n",
    "        con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor.execute('''CREATE TABLE IF NOT EXISTS titles_authors (\n",
    "                isbn_13 text primary key,\n",
    "                author_id text\n",
    "               );''')\n",
    "\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor.execute('''SELECT isbn_10 FROM titles;''')\n",
    "titles = cursor.fetchall()\n",
    "titles = [title[0] for title in titles]\n",
    "titles = [title.lower() for title in titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for title in titles:\n",
    "    if ('' in title):\n",
    "        print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor.execute('''SELECT author_name FROM authors;''')\n",
    "authors = cursor.fetchall()\n",
    "authors = [author[0] for author in authors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for author in authors:\n",
    "    if('randon' in author) and ('anderson' in author):\n",
    "        print(author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### isbn-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor.execute('''SELECT isbn_10 FROM titles;''')\n",
    "titles = cursor.fetchall()\n",
    "titles = [title[0] for title in titles]\n",
    "titles = [title.lower() for title in titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for title in titles:\n",
    "    if '0886773849' in title:\n",
    "        print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
