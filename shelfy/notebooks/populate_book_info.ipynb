{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import sys\n",
    "\n",
    "\n",
    "import numpy\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "\n",
    "\n",
    "import shelfy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create SQL DB connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://postgres:password@localhost:5432/book_info\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Define a database name (we're using a dataset on births, so we'll call it birth_db)\n",
    "# Set your postgres username/password, and connection specifics\n",
    "username = 'postgres'\n",
    "password = 'password'     # change this\n",
    "host     = 'localhost'\n",
    "port     = '5432'            # default port that postgres listens on\n",
    "db_name  = 'book_info'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 'engine' is a connection to a database\n",
    "## Here, we're using postgres, but sqlalchemy can connect to other things too.\n",
    "engine = create_engine( 'postgresql://{}:{}@{}:{}/{}'.format(username, password, host, port, db_name) )\n",
    "print(engine.url)\n",
    "\n",
    "\n",
    "## create a database (if it doesn't exist)\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "print(database_exists(engine.url))\n",
    "\n",
    "\n",
    "\n",
    "# Create connection and cursor object to insert info into db\n",
    "con = psycopg2.connect(database = db_name, user = username, password = password, host = host)\n",
    "cursor = con.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create titles table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the tables (if don't exist)\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS works (\n",
    "                index BIGSERIAL PRIMARY KEY,\n",
    "                titles TEXT);''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS editions (\n",
    "                index BIGSERIAL PRIMARY KEY,\n",
    "                titles TEXT);''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS authors (\n",
    "                index BIGSERIAL PRIMARY KEY,\n",
    "                authors TEXT);''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS publishers (\n",
    "                index BIGSERIAL PRIMARY KEY,\n",
    "                publishers TEXT);''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS words (\n",
    "                index BIGSERIAL PRIMARY KEY,\n",
    "                word TEXT,\n",
    "                idf real);''')\n",
    "\n",
    "\n",
    "# Have to commit the table creation\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fill titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Works\n",
    "command = '''INSERT INTO works (titles) VALUES (%s);'''\n",
    "\n",
    "\n",
    "titles_path = shelfy.SHELFY_BASE_PATH + '/raw_data/dumps/' + 'ol_dump_works_2017-12-31.txt'\n",
    "\n",
    "\n",
    "num_fails = 0\n",
    "with open(titles_path, 'r') as file_handle:\n",
    "    \n",
    "    for row in file_handle:\n",
    "        try:\n",
    "            title = json.loads(row.split('\\t')[-1])['title']\n",
    "            cursor.execute(command, (title,))\n",
    "            con.commit()\n",
    "        except:\n",
    "            num_fails += 1\n",
    "            print('failed', num_fails)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fill editions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Editions\n",
    "\n",
    "command = '''INSERT INTO editions (titles) VALUES (%s);'''\n",
    "\n",
    "\n",
    "titles_path = shelfy.SHELFY_BASE_PATH + '/raw_data/dumps/' + 'ol_dump_editions_2017-12-31.txt'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_fails = 0\n",
    "with open(titles_path, 'r') as file_handle:\n",
    "    \n",
    "    \n",
    "    i = 0\n",
    "    # Open reader object to parse file\n",
    "    for row in file_handle:\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        try:\n",
    "            title = json.loads(row.split('\\t')[4])['title']\n",
    "            cursor.execute(command, (title,))\n",
    "            \n",
    "        except:\n",
    "            num_fails += 1\n",
    "            print('failed', num_fails)\n",
    "            pass\n",
    "        \n",
    "        if i % 10000 == 0:\n",
    "            print('dumping 100000')\n",
    "            con.commit()\n",
    "            i = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Fill authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Editions\n",
    "\n",
    "command = '''INSERT INTO authors (authors) VALUES (%s);'''\n",
    "\n",
    "\n",
    "titles_path = shelfy.SHELFY_BASE_PATH + '/raw_data/dumps/' + 'ol_dump_authors_2017-12-31.txt'\n",
    "\n",
    "\n",
    "num_fails = 0\n",
    "with open(titles_path, 'r') as file_handle:\n",
    "    \n",
    "    \n",
    "    i = 0\n",
    "    # Open reader object to parse file\n",
    "    for row in file_handle:\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        try:\n",
    "            author = json.loads(row.split('\\t')[4])['name']\n",
    "            cursor.execute(command, (author,))\n",
    "            \n",
    "        except:\n",
    "            num_fails += 1\n",
    "            print('failed', num_fails)\n",
    "        \n",
    "        if i % 100000 == 0:\n",
    "            print('dumping 100000')\n",
    "            con.commit()\n",
    "            i = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fill publishers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Publishers\n",
    "\n",
    "command = '''INSERT INTO publishers (publishers) VALUES (%s);'''\n",
    "\n",
    "\n",
    "titles_path = shelfy.SHELFY_BASE_PATH + '/raw_data/dumps/' + 'ol_dump_editions_2017-12-31.txt'\n",
    "\n",
    "\n",
    "num_fails = 0\n",
    "with open(titles_path, 'r') as file_handle:\n",
    "    \n",
    "    \n",
    "    i = 0\n",
    "    # Open reader object to parse file\n",
    "    for row in file_handle:\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        try:\n",
    "            publisher = json.loads(row.split('\\t')[4])['publishers'][0]\n",
    "            \n",
    "            cursor.execute(command, (publisher,))\n",
    "            \n",
    "        except:\n",
    "            num_fails += 1\n",
    "            #print('failed', num_fails)\n",
    "        \n",
    "        if i % 100000 == 0:\n",
    "            \n",
    "            print('dumping 100000')\n",
    "            con.commit()\n",
    "            i = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.feature_extraction.text\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import sys\n",
    "\n",
    "\n",
    "import numpy\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "\n",
    "\n",
    "import shelfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://postgres:password@localhost:5432/book_info\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Define a database name (we're using a dataset on births, so we'll call it birth_db)\n",
    "# Set your postgres username/password, and connection specifics\n",
    "username = 'postgres'\n",
    "password = 'password'     # change this\n",
    "host     = 'localhost'\n",
    "port     = '5432'            # default port that postgres listens on\n",
    "db_name  = 'book_info'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 'engine' is a connection to a database\n",
    "## Here, we're using postgres, but sqlalchemy can connect to other things too.\n",
    "engine = create_engine( 'postgresql://{}:{}@{}:{}/{}'.format(username, password, host, port, db_name) )\n",
    "print(engine.url)\n",
    "\n",
    "\n",
    "## create a database (if it doesn't exist)\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "print(database_exists(engine.url))\n",
    "\n",
    "\n",
    "\n",
    "# Create connection and cursor object to insert info into db\n",
    "con = psycopg2.connect(database = db_name, user = username, password = password, host = host)\n",
    "cursor = con.cursor()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le Contrat réalisable\n",
      "Combating Surgical Infection\n",
      "Chirurgie implantaire\n",
      "One coffee with\n",
      "La 7e porte\n",
      "Les gens de la vallee\n",
      "Le Cerveau bleu\n",
      "A la recherche de l'âme de mon père\n",
      "Hématologie et soins infirmiers\n",
      "L' apprentissage du vocabulaire médical\n",
      "L'Agartha? mythe ou réalité?\n",
      "Football\n",
      "Livre de la belote (le)\n",
      "Die Moxa - Therapie. Wärmepunktur - Eine klassische chinesische Heilmethode\n",
      "Dominique delise\n",
      "The man from Thrush\n",
      "Offrandes De La Mer\n",
      "La grande encyclopédie du dérisoire, tome 1\n",
      "W swiecie polszczyzny\n",
      "Guide des sources d'information\n",
      "Invention du hottentot histoire du regard occidental sur les khoisan XV-XIX\n",
      "De philippe auguste a la mort de charles V\n",
      "Choisir et poser portes et fenêtres\n",
      "Manufactura Justo a Tiempo - Enfoque Practico\n",
      "De natura\n",
      "Der Korb\n",
      "Le travail du sucre, tome 2\n",
      "Les défis de la travailleuse familiale\n",
      "Jean Vigo\n",
      "Thaïlande\n",
      "Locations meublées et locations saisonnières\n",
      "Donna Parker on her Own\n",
      "Analyse statistique des donnees experimentales\n",
      "Le nouveau menoza\n",
      "The Study of Africa Volume 1\n",
      "Feliz Dia!\n",
      "Write Your Business Plan!\n",
      "Pygmées d'Afrique Centrale\n",
      "Les meilleures soupes\n",
      "Mémoire cavalière\n",
      "La vérité sur les cosmétiques\n",
      "Cuisine basque\n",
      "La cuisine des mousquetaires, tome 2\n",
      "Méthodes multicritères ELECTRE\n",
      "J'ai pas sommeil !\n",
      "Victoires sur soi\n",
      "Antologia Musical\n",
      "Animal Folk Songs for Children\n",
      "Middle East:A Closer Look/Cav\n",
      "Les risques du voyage\n",
      "Des hectares de diamants\n",
      "Sculptures by Henry Moore\n",
      "Poésie et réalité\n",
      "Pratique homéopathique en psychopathologie, tome 2\n",
      "Le Ménagier de Paris. Traité de morale et d'économie domestique composé vers 1393 par un bourgeois parisien, tomes 1 et 2\n",
      "Aimants et pâte à sel\n",
      "Putain d usine\n",
      "Guide pratique du Musulman\n",
      "La visualisation\n",
      "Devenir manager\n",
      "Letterwork\n",
      "Quelque part dans les balkans\n",
      "Le Crime de Kergroise\n",
      "Les droits d'auteur\n",
      "Marcel Proust Du Cote de Cabourg\n",
      ".45-Caliber Deathtrap\n",
      "Oeuvres\n",
      "Douleur et cancer\n",
      "David Crockett\n",
      "Etre femme en Périgord au XIXème siecle\n",
      "LA ROUTE MORTE\n",
      "Le cuisinier landais precede de lettres a mon gendre et nouvelles lettres a mon gendre\n",
      "Romancero de Champagne\n",
      "Sur la Route de la Nouvelle-France\n",
      "World Competitiveness Yearbook 1999\n",
      "Ganzheitliches Beckenbodentraining für Frauen aller Altersstufen\n",
      "Catch your Dream. Amerika, seine Menschen und ich\n",
      "Missa Solemnis. Mord auf dem Dorf. Roman\n",
      "Transcultural Wars from the Middle Ages to the 21st Century\n",
      "Unsere Welt, Mensch und Raum, Große Ausgabe, Atlas für Sachsen-Anhalt\n",
      "Lehrbuch der Chorleitung, 3 Bde., Bd.3\n",
      "Simone de Beauvoir\n",
      "Iwein\n",
      "Handelsgesetzbuch, Grosskommentar, 5\n",
      "Eustathii Thessalonicensis Opera Minora\n",
      "Die Kirchengemeinde, Sozialsystem im Wandel\n",
      "Anonyme Kirchengeschichte\n",
      "Romische Erinnerungsraume Heiligenmemoria Und Kollektive Identitaten Im Rom Des 3 Bis 5 Jahrhunderts N Chr (Millennium Studien/Millennium Studies)\n",
      "Phaedrus. Fabeln.\n",
      "Matherhorn 2. 9./10. Schuljahr. 111 Aufgaben zur Begabtenförderung.\n",
      "Enemies Within Us\n",
      "Deus sobre as pedras\n",
      "Little Drummer Boy\n",
      "Training, Lineare Algebra und Analytische Geometrie, Sekundarstufe II\n",
      "El desarrollo del comercio y las inversiones entre Brasil y Venezuela\n",
      "Unteroffiziere und Gemeine der Fürstbischöflich-Münterischen Armee von 1775 bis zu ihrer Auflösung 1802\n",
      "Leporello, Allgemeine Ausgabe, neue Rechtschreibung, Übungsteil zur Fibel\n",
      "Jokes. Witze im Englischunterricht.\n",
      "Geschichte der Philosophie IV in Text und Darstellung. Empirismus\n",
      "Aisthesis vor Platon\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# Get editions\\ncommand = 'SELECT titles FROM editions;'\\ncursor.execute(command)\\nworks = cursor.fetchall()\\n\\n# Get authors\\ncommand = 'SELECT titles FROM editions;'\\ncursor.execute(command)\\nauthors = cursor.fetchall()\\n\\n# Get publishers\\ncommand = 'SELECT titles FROM editions;'\\ncursor.execute(command)\\npublishers = cursor.fetchall()\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get works\n",
    "command = 'SELECT titles FROM works;'\n",
    "cursor.execute(command)\n",
    "works = cursor.fetchall()\n",
    "works = [work[0] for work in works]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    print(works[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "        input=[('Le Contrat réalisable',), ('Combating Surgical Infection',), ('Chirurgie implantaire',), ('One coffee with',), ('La 7e porte',), ('Les gens de la vallee',), ('Le Cerveau bleu',), (\"A la recherche de l'âme de mon père\",), ('Hématologie et soins infirmiers',), (\"L' apprentissage du vocabulair...hie',), ('Babel Ouest',), ('La promise',), ('Le Peintre et le Pirate',), ('Collage de serviettes',)],\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = sklearn.feature_extraction.text.TfidfVectorizer(works, strip_accents = 'ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Le Contrat réalisable',)\n"
     ]
    }
   ],
   "source": [
    "print(works[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
