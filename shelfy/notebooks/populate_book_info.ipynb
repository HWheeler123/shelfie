{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import sys\n",
    "\n",
    "\n",
    "import numpy\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "\n",
    "\n",
    "import shelfy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create SQL DB connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgresql://postgres:password@localhost:5432/book_info\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Define a database name (we're using a dataset on births, so we'll call it birth_db)\n",
    "# Set your postgres username/password, and connection specifics\n",
    "username = 'postgres'\n",
    "password = 'password'     # change this\n",
    "host     = 'localhost'\n",
    "port     = '5432'            # default port that postgres listens on\n",
    "db_name  = 'book_info'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 'engine' is a connection to a database\n",
    "## Here, we're using postgres, but sqlalchemy can connect to other things too.\n",
    "engine = create_engine( 'postgresql://{}:{}@{}:{}/{}'.format(username, password, host, port, db_name) )\n",
    "print(engine.url)\n",
    "\n",
    "\n",
    "## create a database (if it doesn't exist)\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "print(database_exists(engine.url))\n",
    "\n",
    "\n",
    "\n",
    "# Create connection and cursor object to insert info into db\n",
    "con = psycopg2.connect(database = db_name, user = username, password = password, host = host)\n",
    "cursor = con.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create titles table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the tables (if don't exist)\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS works (\n",
    "                index BIGSERIAL PRIMARY KEY,\n",
    "                titles TEXT);''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS editions (\n",
    "                index BIGSERIAL PRIMARY KEY,\n",
    "                titles TEXT);''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS authors (\n",
    "                index BIGSERIAL PRIMARY KEY,\n",
    "                authors TEXT);''')\n",
    "\n",
    "cursor.execute('''CREATE TABLE IF NOT EXISTS publishers (\n",
    "                index BIGSERIAL PRIMARY KEY,\n",
    "                publishers TEXT);''')\n",
    "\n",
    "\n",
    "# Have to commit the table creation\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fill titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed 1\n",
      "failed 2\n",
      "failed 3\n",
      "failed 4\n",
      "failed 5\n",
      "failed 6\n"
     ]
    }
   ],
   "source": [
    "# Works\n",
    "command = '''INSERT INTO works (titles) VALUES (%s);'''\n",
    "\n",
    "\n",
    "titles_path = shelfy.SHELFY_BASE_PATH + '/raw_data/dumps/' + 'ol_dump_works_2017-12-31.txt'\n",
    "\n",
    "\n",
    "num_fails = 0\n",
    "with open(titles_path, 'r') as file_handle:\n",
    "    \n",
    "    for row in file_handle:\n",
    "        try:\n",
    "            title = json.loads(row.split('\\t')[-1])['title']\n",
    "            cursor.execute(command, (title,))\n",
    "            con.commit()\n",
    "        except:\n",
    "            num_fails += 1\n",
    "            print('failed', num_fails)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fill editions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Editions\n",
    "\n",
    "command = '''INSERT INTO editions (titles) VALUES (%s);'''\n",
    "\n",
    "\n",
    "titles_path = shelfy.SHELFY_BASE_PATH + '/raw_data/dumps/' + 'ol_dump_editions_2017-12-31.txt'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_fails = 0\n",
    "with open(titles_path, 'r') as file_handle:\n",
    "    # Open reader object to parse file\n",
    "    reader = csv.reader(file_handle, delimiter = '\\t', quoting=csv.QUOTE_NONE)\n",
    "    \n",
    "    for row in reader:\n",
    "        try:\n",
    "            title = json.loads(row[4])['title']\n",
    "            cursor.execute(command, (title,))\n",
    "            con.commit()\n",
    "        except:\n",
    "            num_fails += 1\n",
    "            print('failed', num_fails)\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = '../data/jsondump.json'\n",
    "\n",
    "table_name = 'titles'\n",
    "\n",
    "batch_size = 10000\n",
    "\n",
    "with open(file_name, 'r') as file_handle:\n",
    "\n",
    "    ix = 0\n",
    "    while ix < 10:\n",
    "        titles = []\n",
    "        subtitles = [] \n",
    "        authors = []\n",
    "        publishers = []\n",
    "        isbn10s = []\n",
    "        isbns13 = []\n",
    "\n",
    "        print('starting a new block, num_blocks = ', ix)\n",
    "        ix += 1\n",
    "\n",
    "        for i in range(batch_size):\n",
    "\n",
    "            data = next(file_handle)\n",
    "            json_data = json.loads(data)\n",
    "\n",
    "            keys = json_data.keys()\n",
    "\n",
    "            \n",
    "\n",
    "            if json_data['type']['key'] == '/type/edition':\n",
    "\n",
    "\n",
    "                print(json_data)\n",
    "\n",
    "                if 'isbn_13' in keys:\n",
    "                    isbn_13 = json_data['isbn_13'][0]\n",
    "                else:\n",
    "                    isbn_13 = random_isbn()\n",
    "\n",
    "\n",
    "                if 'isbn_10' in keys:\n",
    "                    isbn_10 = json_data['isbn_10'][0]\n",
    "                else:\n",
    "                    isbn_10 = 'NULL'\n",
    "\n",
    "\n",
    "                if 'title' in keys:\n",
    "                    title = json_data['title']\n",
    "                else:\n",
    "                    title = 'NULL'\n",
    "\n",
    "                if 'subtitle' in keys:\n",
    "                    subtitle = json_data['subtitle']\n",
    "                else:\n",
    "                    subtitle = 'NULL'\n",
    "\n",
    "                if 'publishers' in keys:\n",
    "                    publisher = json_data['publishers'][0]\n",
    "                else:\n",
    "                    publisher = []\n",
    "\n",
    "\n",
    "\n",
    "                command = '''\n",
    "                INSERT INTO titles (isbn_13, isbn_10, title, subtitle, publisher) VALUES (%s, %s, %s, %s, %s);\n",
    "                '''\n",
    "\n",
    "                try:\n",
    "                    #cursor.execute(command, (isbn_13, isbn_10, title, subtitle, publisher))\n",
    "                    pass\n",
    "                except Exception as e:\n",
    "                    print(str(e))\n",
    "                    print('error!', ix)\n",
    "                    #con.commit()\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "        con.commit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create titles_2 database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor.execute('''CREATE TABLE IF NOT EXISTS works (\n",
    "                work_key text primary key,\n",
    "                title text\n",
    "               );''')\n",
    "\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = '../data/ol_dump_works_2017-12-31.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(file_name) as file_handle:\n",
    "\n",
    "    while True:\n",
    "        line = next(file_handle)\n",
    "        json_start = line.find('{')\n",
    "        json_data = json.loads(line[json_start:])\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            title = json_data['title']\n",
    "            work_key = json_data['key'].split('/')[-1]\n",
    "    \n",
    "            command = '''\n",
    "            INSERT INTO works (work_key, title) VALUES (%s, %s)\n",
    "            '''\n",
    "        \n",
    "            cursor.execute(command, (work_key, title))\n",
    "            con.commit()\n",
    "        except Exception as e:\n",
    "            print('error')\n",
    "            print(str(e))\n",
    "            con.commit()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('asdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create authors database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor.execute('''CREATE TABLE IF NOT EXISTS authors (\n",
    "                author_id text primary key,\n",
    "                author_name text\n",
    "               );''')\n",
    "\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = '../data/ol_dump_authors_2017-12-31.txt'\n",
    "\n",
    "with open(file_name) as file_handle:\n",
    "    while True:\n",
    "        line = next(file_handle)\n",
    "        author_id = line.split('/authors/')[-1].split(' ')[0].replace('\",', '')\n",
    "        author_name = line.split('{\"name\": ')[-1].split(',')[0].replace('\"','')\n",
    "        \n",
    "        command = '''\n",
    "        INSERT INTO authors (author_id, author_name) VALUES (%s, %s);\n",
    "        '''\n",
    "        \n",
    "        cursor.execute(command, (author_id, author_name))\n",
    "        con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor.execute('''CREATE TABLE IF NOT EXISTS titles_authors (\n",
    "                isbn_13 text primary key,\n",
    "                author_id text\n",
    "               );''')\n",
    "\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor.execute('''SELECT isbn_10 FROM titles;''')\n",
    "titles = cursor.fetchall()\n",
    "titles = [title[0] for title in titles]\n",
    "titles = [title.lower() for title in titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for title in titles:\n",
    "    if ('' in title):\n",
    "        print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor.execute('''SELECT author_name FROM authors;''')\n",
    "authors = cursor.fetchall()\n",
    "authors = [author[0] for author in authors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for author in authors:\n",
    "    if('randon' in author) and ('anderson' in author):\n",
    "        print(author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### isbn-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cursor.execute('''SELECT isbn_10 FROM titles;''')\n",
    "titles = cursor.fetchall()\n",
    "titles = [title[0] for title in titles]\n",
    "titles = [title.lower() for title in titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for title in titles:\n",
    "    if '0886773849' in title:\n",
    "        print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
